{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD PACKAGES\n",
    "using Pkg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Pkg.add(\"CSV\")\n",
    "Pkg.add(\"DataFrames\")\n",
    "Pkg.add(\"FreqTables\")\n",
    "Pkg.add(\"HTTP\")\n",
    "Pkg.add(\"HypothesisTests\")\n",
    "Pkg.add(\"JLD\")\n",
    "Pkg.add(\"MLJBase\")\n",
    "Pkg.add(\"Missings\")\n",
    "Pkg.add(\"Plots\")\n",
    "Pkg.add(\"StatsKit\") # meta-package that loads packages associated with JuliaStats, including CSV, DataFrames, GLM, HypothesisTests,\n",
    "#and MultivariateStats\n",
    "# note: unclear which packages loaded automatically; I used StatsKit without loading CSV directly, and then CSV not available\n",
    "Pkg.add(\"StatsPlots\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Open installed packages\n",
    "using CSV, DataFrames, FreqTables, HTTP, HypothesisTests, JLD, Missings, MLJBase, Plots, StatsKit, StatsPlots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check julia version\n",
    "VERSION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Directory Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/home/jovyan/\"\n",
    "cd(path)\n",
    "# or cd(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Sub-directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mkdir(\"./code\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mkdir(\"./data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mkdir(\"./figures\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mkdir(\"./tables\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "readdir()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if loading from file in data folder (use CSV and DataFrame together)\n",
    "df1 = CSV.read(\"./data/original/metoo_data.csv\", DataFrame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# can index within DataFrame\n",
    "# e.g., \n",
    "# row = df1[1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect first 5 rows and first 3 cols\n",
    "df1[1:5,1:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "describe(df1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create and transform new var condition2\n",
    "df1.condition2 = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1[(df1[:condition] .== 1),:condition2]=\"Jokes\"\n",
    "df1[(df1[:condition] .== 2),:condition2]=\"Assault\"\n",
    "df1[(df1[:condition] .== 3),:condition2]=\"Control\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check values\n",
    "df1[1:5,:condition2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make categorical\n",
    "df1[:condition2] = CategoricalArray(df1[:condition2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check levels\n",
    "levels(df1[:condition2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reorder levels\n",
    "levels!(df1[:condition2], [\"Control\", \"Jokes\", \"Assault\"])\n",
    "# exclamation mark (!) after function replaces object in place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recheck levels\n",
    "levels(df1[:condition2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create and transform new var pid3\n",
    "# check tabulation (values)\n",
    "freqtable(df1.pid7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.pid3 = \"\"\n",
    "df1[(df1[:pid7] .== \"Lean Democrat\"),:pid3]=\"Democrat\"\n",
    "df1[(df1[:pid7] .== \"Strong Democrat\"),:pid3]=\"Democrat\"\n",
    "df1[(df1[:pid7] .== \"Not very strong Democrat\"),:pid3]=\"Democrat\"\n",
    "\n",
    "df1[(df1[:pid7] .== \"Lean Republican\"),:pid3]=\"Republican\"\n",
    "df1[(df1[:pid7] .== \"Strong Republican\"),:pid3]=\"Republican\"\n",
    "df1[(df1[:pid7] .== \"Not very strong Republican\"),:pid3]=\"Republican\"\n",
    "\n",
    "df1[(df1[:pid7] .== \"Independent\"),:pid3]=\"Independent\"\n",
    "df1[(df1[:pid7] .== \"Not sure\"),:pid3]=\"Independent\"\n",
    "\n",
    "# make categorical\n",
    "df1[:pid3] = CategoricalArray(df1[:pid3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "describe(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recode: punishment \n",
    "\n",
    "# punishment 1\n",
    "freqtable(df1.punishment_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# var contains 'missing', which will not process in ==/> kind of functions, so need to recode missing first as \"\"\n",
    "df1.punishment_1b = df1.punishment_1\n",
    "df1.punishment_1b = Missings.replace(df1.punishment_1b, \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recode: punishment \n",
    "\n",
    "# punishment 1\n",
    "df1.needmoreevidence = 999\n",
    "df1[(df1[:punishment_1b] .== \"Agree strongly\"),:needmoreevidence]=5\n",
    "df1[(df1[:punishment_1b] .== \"Agree somewhat\"),:needmoreevidence]=4\n",
    "df1[(df1[:punishment_1b] .== \"Neither disagree nor agree\"),:needmoreevidence]=3\n",
    "df1[(df1[:punishment_1b] .== \"Disagree somewhat\"),:needmoreevidence]=2\n",
    "df1[(df1[:punishment_1b] .== \"Disagree strongly\"),:needmoreevidence]=1\n",
    "\n",
    "# now recode 999 as missing so future fxn will skip over\n",
    "df1[:needmoreevidence] = recode(df1[:needmoreevidence], 999=>missing)\n",
    "\n",
    "freqtable(df1.needmoreevidence, df1.punishment_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# punishment 2 (to 'apology')\n",
    "freqtable(df1.punishment_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# var contains 'missing', which will not process in ==/> kind of functions, so need to recode missing first as \"\"\n",
    "df1.punishment_2b = df1.punishment_2\n",
    "df1.punishment_2b = Missings.replace(df1.punishment_2b, \"\")\n",
    "\n",
    "df1.apology = 999\n",
    "df1[(df1[:punishment_2b] .== \"Agree strongly\"),:apology]=5\n",
    "df1[(df1[:punishment_2b] .== \"Agree somewhat\"),:apology]=4\n",
    "df1[(df1[:punishment_2b] .== \"Neither disagree nor agree\"),:apology]=3\n",
    "df1[(df1[:punishment_2b] .== \"Disagree somewhat\"),:apology]=2\n",
    "df1[(df1[:punishment_2b] .== \"Disagree strongly\"),:apology]=1\n",
    "\n",
    "# recode 999 as missing\n",
    "df1[:apology] = recode(df1[:apology], 999=>missing)\n",
    "freqtable(df1.apology, df1.punishment_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# punishment 3 (to 'longtimeago')\n",
    "freqtable(df1.punishment_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# var contains 'missing', which will not process in ==/> kind of functions, so need to recode missing first as \"\"\n",
    "df1.punishment_3b = df1.punishment_3\n",
    "df1.punishment_3b = Missings.replace(df1.punishment_3b, \"\")\n",
    "\n",
    "df1.longtimeago = 999\n",
    "df1[(df1[:punishment_3b] .== \"Agree strongly\"),:longtimeago]=5\n",
    "df1[(df1[:punishment_3b] .== \"Agree somewhat\"),:longtimeago]=4\n",
    "df1[(df1[:punishment_3b] .== \"Neither disagree nor agree\"),:longtimeago]=3\n",
    "df1[(df1[:punishment_3b] .== \"Disagree somewhat\"),:longtimeago]=2\n",
    "df1[(df1[:punishment_3b] .== \"Disagree strongly\"),:longtimeago]=1\n",
    "\n",
    "# recode 999 as missing\n",
    "df1[:longtimeago] = recode(df1[:longtimeago], 999=>missing)\n",
    "freqtable(df1.longtimeago, df1.punishment_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# punishment 4 (to 'resign')\n",
    "freqtable(df1.punishment_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# var contains 'missing', which will not process in ==/> kind of functions, so need to recode missing first as \"\"\n",
    "df1.punishment_4b = df1.punishment_4\n",
    "df1.punishment_4b = Missings.replace(df1.punishment_4b, \"\")\n",
    "\n",
    "df1.resign = 999\n",
    "df1[(df1[:punishment_4b] .== \"Agree strongly\"),:resign]=5\n",
    "df1[(df1[:punishment_4b] .== \"Agree somewhat\"),:resign]=4\n",
    "df1[(df1[:punishment_4b] .== \"Neither disagree nor agree\"),:resign]=3\n",
    "df1[(df1[:punishment_4b] .== \"Disagree somewhat\"),:resign]=2\n",
    "df1[(df1[:punishment_4b] .== \"Disagree strongly\"),:resign]=1\n",
    "\n",
    "# recode 999 as missing\n",
    "df1[:resign] = recode(df1[:resign], 999=>missing)\n",
    "freqtable(df1.resign, df1.punishment_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# punishment 5 (to 'elitecues')\n",
    "freqtable(df1.punishment_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# var contains 'missing', which will not process in ==/> kind of functions, so need to recode missing first as \"\"\n",
    "df1.punishment_5b = df1.punishment_5\n",
    "df1.punishment_5b = Missings.replace(df1.punishment_5b, \"\")\n",
    "\n",
    "df1.elitecues = 999\n",
    "df1[(df1[:punishment_5b] .== \"Agree strongly\"),:elitecues]=5\n",
    "df1[(df1[:punishment_5b] .== \"Agree somewhat\"),:elitecues]=4\n",
    "df1[(df1[:punishment_5b] .== \"Neither disagree nor agree\"),:elitecues]=3\n",
    "df1[(df1[:punishment_5b] .== \"Disagree somewhat\"),:elitecues]=2\n",
    "df1[(df1[:punishment_5b] .== \"Disagree strongly\"),:elitecues]=1\n",
    "\n",
    "# recode 999 as missing\n",
    "df1[:elitecues] = recode(df1[:elitecues], 999=>missing)\n",
    "freqtable(df1.elitecues, df1.punishment_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################\n",
    "# recode punishment: reverse codes\n",
    "#############################\n",
    "\n",
    "# need more evidence\n",
    "df1.needmoreevidence_reverse = 999\n",
    "df1[(df1[:punishment_1b] .== \"Agree strongly\"),:needmoreevidence_reverse]=1\n",
    "df1[(df1[:punishment_1b] .== \"Agree somewhat\"),:needmoreevidence_reverse]=2\n",
    "df1[(df1[:punishment_1b] .== \"Neither disagree nor agree\"),:needmoreevidence_reverse]=3\n",
    "df1[(df1[:punishment_1b] .== \"Disagree somewhat\"),:needmoreevidence_reverse]=4\n",
    "df1[(df1[:punishment_1b] .== \"Disagree strongly\"),:needmoreevidence_reverse]=5\n",
    "\n",
    "# now recode 999 as missing so future fxn will skip over\n",
    "df1[:needmoreevidence_reverse] = recode(df1[:needmoreevidence_reverse], 999=>missing)\n",
    "\n",
    "freqtable(df1.needmoreevidence_reverse, df1.punishment_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# long time ago\n",
    "df1.longtimeago_reverse = 999\n",
    "df1[(df1[:punishment_3b] .== \"Agree strongly\"),:longtimeago_reverse]=1\n",
    "df1[(df1[:punishment_3b] .== \"Agree somewhat\"),:longtimeago_reverse]=2\n",
    "df1[(df1[:punishment_3b] .== \"Neither disagree nor agree\"),:longtimeago_reverse]=3\n",
    "df1[(df1[:punishment_3b] .== \"Disagree somewhat\"),:longtimeago_reverse]=4\n",
    "df1[(df1[:punishment_3b] .== \"Disagree strongly\"),:longtimeago_reverse]=5\n",
    "\n",
    "# recode 999 as missing\n",
    "df1[:longtimeago_reverse] = recode(df1[:longtimeago_reverse], 999=>missing)\n",
    "freqtable(df1.longtimeago_reverse, df1.punishment_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new variable: mean punitiveness score ####\n",
    "df1[:meanpunishment] = ((df1[:apology]+df1[:resign]+df1[:needmoreevidence_reverse]+df1[:longtimeago_reverse])/4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "describe(df1.meanpunishment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## new variable: same party as legislator####\n",
    "freqtable(df1.senator_party, df1.senator_party)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.sameparty = \"\"\n",
    "df1[( (df1[:pid3] .== \"Democrat\") .& (df1[:senator_party] .== \"Democrat\") ) .|\n",
    "    ( (df1[:pid3] .== \"Republican\") .& (df1[:senator_party] .== \"Republican\") ),:sameparty] =\"Same party\"\n",
    "\n",
    "df1[( (df1[:pid3] .== \"Democrat\") .& (df1[:senator_party] .== \"Republican\") ) .|\n",
    "    ( (df1[:pid3] .== \"Republican\") .& (df1[:senator_party] .== \"Democrat\") ),:sameparty] =\"Opposite party\"\n",
    "\n",
    "df1[(df1[:pid3] .== \"Independent\"),:sameparty] = \"Independents/Not sures\" \n",
    "\n",
    "#make categorical\n",
    "df1[:sameparty] = CategoricalArray(df1[:sameparty])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freqtable(df1.sameparty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recode: pre sexism ####\n",
    "# sexism_1,2,4 reverse coded\n",
    "# see original R code from authors\n",
    "\n",
    "# tried using recode and dictionaries, but could not get it to work\n",
    "# instead, generated simple numeric based on values of pre_sexism_#\n",
    "\n",
    "#df1.pre_sexism_1new = recode(df1.pre_sexism_1, \n",
    "#    5=>\"Agree strongly\",\n",
    "#    4=>\"Agree somewhat\",\n",
    "#    3=>\"Neither disagree nor agree\",\n",
    "#    2=>\"Disagree somewhat\",\n",
    "#    1=>\"Disagree strongly\")\n",
    "\n",
    "# alt: could use dictionary: A = Categorical([1 2;2 1;2 2;1 1], Dict(1=>\"male\", 2=>\"female\"))\n",
    "\n",
    "df1.pre_sexism_1new = 999\n",
    "df1[ (df1[:pre_sexism_1] .== \"Agree strongly\"),:pre_sexism_1new] =5\n",
    "df1[ (df1[:pre_sexism_1] .== \"Agree somewhat\"),:pre_sexism_1new] =4\n",
    "df1[ (df1[:pre_sexism_1] .== \"Neither disagree nor agree\"),:pre_sexism_1new] =3\n",
    "df1[ (df1[:pre_sexism_1] .== \"Disagree somewhat\"),:pre_sexism_1new] =2\n",
    "df1[ (df1[:pre_sexism_1] .== \"Disagree strongly\"),:pre_sexism_1new] =1\n",
    "freqtable(df1.pre_sexism_1new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.pre_sexism_2new = 999\n",
    "df1[ (df1[:pre_sexism_2] .== \"Agree strongly\"),:pre_sexism_2new] =5\n",
    "df1[ (df1[:pre_sexism_2] .== \"Agree somewhat\"),:pre_sexism_2new] =4\n",
    "df1[ (df1[:pre_sexism_2] .== \"Neither disagree nor agree\"),:pre_sexism_2new] =3\n",
    "df1[ (df1[:pre_sexism_2] .== \"Disagree somewhat\"),:pre_sexism_2new] =2\n",
    "df1[ (df1[:pre_sexism_2] .== \"Disagree strongly\"),:pre_sexism_2new] =1\n",
    "freqtable(df1.pre_sexism_2new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.pre_sexism_4new = 999\n",
    "df1[ (df1[:pre_sexism_4] .== \"Agree strongly\"),:pre_sexism_4new] =5\n",
    "df1[ (df1[:pre_sexism_4] .== \"Agree somewhat\"),:pre_sexism_4new] =4\n",
    "df1[ (df1[:pre_sexism_4] .== \"Neither disagree nor agree\"),:pre_sexism_4new] =3\n",
    "df1[ (df1[:pre_sexism_4] .== \"Disagree somewhat\"),:pre_sexism_4new] =2\n",
    "df1[ (df1[:pre_sexism_4] .== \"Disagree strongly\"),:pre_sexism_4new] =1\n",
    "freqtable(df1.pre_sexism_4new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.pre_sexism_3new = 999\n",
    "df1[ (df1[:pre_sexism_3] .== \"Agree strongly\"),:pre_sexism_3new] =1\n",
    "df1[ (df1[:pre_sexism_3] .== \"Agree somewhat\"),:pre_sexism_3new] =2\n",
    "df1[ (df1[:pre_sexism_3] .== \"Neither disagree nor agree\"),:pre_sexism_3new] =3\n",
    "df1[ (df1[:pre_sexism_3] .== \"Disagree somewhat\"),:pre_sexism_3new] =4\n",
    "df1[ (df1[:pre_sexism_3] .== \"Disagree strongly\"),:pre_sexism_3new] =5\n",
    "freqtable(df1.pre_sexism_3new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new variable: pre_sexism ####\n",
    "df1[:pre_sexism] = ((df1[:pre_sexism_1new] + df1[:pre_sexism_2new] + df1[:pre_sexism_3new] + df1[:pre_sexism_4new])/4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recode post_sexism\n",
    "# sexism_1,2,4 reverse coded (same as pre_sexism)\n",
    "# see original R code from authors\n",
    "\n",
    "df1.post_sexism_1new = 999\n",
    "df1[ (df1[:post_sexism_1] .== \"Agree strongly\"),:post_sexism_1new] =5\n",
    "df1[ (df1[:post_sexism_1] .== \"Agree somewhat\"),:post_sexism_1new] =4\n",
    "df1[ (df1[:post_sexism_1] .== \"Neither disagree nor agree\"),:post_sexism_1new] =3\n",
    "df1[ (df1[:post_sexism_1] .== \"Disagree somewhat\"),:post_sexism_1new] =2\n",
    "df1[ (df1[:post_sexism_1] .== \"Disagree strongly\"),:post_sexism_1new] =1\n",
    "\n",
    "df1.post_sexism_2new = 999\n",
    "df1[ (df1[:post_sexism_2] .== \"Agree strongly\"),:post_sexism_2new] =5\n",
    "df1[ (df1[:post_sexism_2] .== \"Agree somewhat\"),:post_sexism_2new] =4\n",
    "df1[ (df1[:post_sexism_2] .== \"Neither disagree nor agree\"),:post_sexism_2new] =3\n",
    "df1[ (df1[:post_sexism_2] .== \"Disagree somewhat\"),:post_sexism_2new] =2\n",
    "df1[ (df1[:post_sexism_2] .== \"Disagree strongly\"),:post_sexism_2new] =1\n",
    "\n",
    "df1.post_sexism_4new = 999\n",
    "df1[ (df1[:post_sexism_4] .== \"Agree strongly\"),:post_sexism_4new] =5\n",
    "df1[ (df1[:post_sexism_4] .== \"Agree somewhat\"),:post_sexism_4new] =4\n",
    "df1[ (df1[:post_sexism_4] .== \"Neither disagree nor agree\"),:post_sexism_4new] =3\n",
    "df1[ (df1[:post_sexism_4] .== \"Disagree somewhat\"),:post_sexism_4new] =2\n",
    "df1[ (df1[:post_sexism_4] .== \"Disagree strongly\"),:post_sexism_4new] =1\n",
    "\n",
    "df1.post_sexism_3new = 999\n",
    "df1[ (df1[:post_sexism_3] .== \"Agree strongly\"),:post_sexism_3new] =1\n",
    "df1[ (df1[:post_sexism_3] .== \"Agree somewhat\"),:post_sexism_3new] =2\n",
    "df1[ (df1[:post_sexism_3] .== \"Neither disagree nor agree\"),:post_sexism_3new] =3\n",
    "df1[ (df1[:post_sexism_3] .== \"Disagree somewhat\"),:post_sexism_3new] =4\n",
    "df1[ (df1[:post_sexism_3] .== \"Disagree strongly\"),:post_sexism_3new] =5\n",
    "\n",
    "# new variable: post_sexism ####\n",
    "df1[:post_sexism] = ((df1[:post_sexism_1new] + df1[:post_sexism_2new] + df1[:post_sexism_3new] + df1[:post_sexism_4new])/4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### new variables: \n",
    "# raw change from pretest to posttest ####\n",
    "# favorability\n",
    "df1[:change_favorability] = (df1.post_favorability.+1) - (df1.pre_favorability.+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vote\n",
    "df1[:change_vote] = (df1.post_vote) - (df1.pre_vote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sexism\n",
    "df1[:change_sexism] = (df1.post_sexism) - (df1.pre_sexism)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### new variables: \n",
    "# percent change from pretest to posttest ##### favorability\n",
    "df1[:perchange_favorability] = (((df1[:post_favorability].+1) - (df1[:pre_favorability].+1))./(df1[:pre_favorability].+1))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vote\n",
    "df1[:perchange_vote] = (((df1.post_vote.+1) - (df1.pre_vote.+1))./(df1.pre_vote.+1))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sexism\n",
    "df1[:perchange_sexism] = (((df1[:post_sexism].+1) - (df1[:pre_sexism].+1))./(df1[:pre_sexism].+1))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subset: without independents/notsures \n",
    "partydat = df1[(df1[:sameparty] .!= \"Independents/Not sures\"),:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subset: people that share party with senator, people that do not share party with senator\n",
    "samepartydat = df1[(df1[:sameparty] .!= \"Same party\"),:]\n",
    "opppartydat = df1[(df1[:sameparty] .!= \"Opposite party\"),:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Means and T-tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Means\n",
    "describe(df1[:post_favorability][df1.condition2 .== \"Control\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "describe(df1[:post_favorability][df1.condition2 .== \"Assault\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "describe(df1[:post_favorability][df1.condition2 .== \"Jokes\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "describe(df1[:post_vote][df1.condition2 .== \"Control\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "describe(df1[:post_vote][df1.condition2 .== \"Assault\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "describe(df1[:post_vote][df1.condition2 .== \"Jokes\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t-tests\n",
    "EqualVarianceTTest(df1[:post_favorability][df1.condition2 .== \"Control\"],\n",
    "    df1[:post_favorability][df1.condition2 .== \"Assault\"])\n",
    "# shows mean difference of 2.7 (same as on p3 of publication), and p<0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EqualVarianceTTest(df1[:post_favorability][df1.condition2 .== \"Control\"],\n",
    "    df1[:post_favorability][df1.condition2 .== \"Jokes\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EqualVarianceTTest(df1[:post_favorability][df1.condition2 .== \"Jokes\"],\n",
    "    df1[:post_favorability][df1.condition2 .== \"Assault\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EqualVarianceTTest(df1[:post_vote][df1.condition2 .== \"Control\"],\n",
    "    df1[:post_vote][df1.condition2 .== \"Assault\"])\n",
    "# shows mean difference of 2.2, again matching p3 of publication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EqualVarianceTTest(df1[:post_vote][df1.condition2 .== \"Control\"],\n",
    "    df1[:post_vote][df1.condition2 .== \"Jokes\"])\n",
    "# this results is a little different from pub (1.4 vs 1.3), but still same general finding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EqualVarianceTTest(df1[:post_vote][df1.condition2 .== \"Jokes\"],\n",
    "    df1[:post_vote][df1.condition2 .== \"Assault\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results: Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OLS estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 1\n",
    "# note: check again; in model and figure, looks like same party coefs are larger than opposite party ones, yet\n",
    "# publication report opposite in Fig 1 (p4)\n",
    "# might just be labelling issue\n",
    "\n",
    "# using GLM, which calls StatsModels\n",
    "# GLM syntax is closer to basic R syntax of lm()\n",
    "\n",
    "# if use StatsModels directly, syntax is:\n",
    "#m1a = fit(LinearModel, @formula(perchange_favorability ~ condition2), samepartydat)\n",
    "#m1b = fit(LinearModel, @formula(perchange_favorability ~ condition2), opppartydat)\n",
    "\n",
    "# using GLM\n",
    "\n",
    "m1a = lm(@formula(perchange_favorability ~ condition2), samepartydat)\n",
    "m1b = lm(@formula(perchange_favorability ~ condition2), opppartydat)\n",
    "m1a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m1b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no package to plot coefficients (e.g., coefplot in R or Stata) or interactions (e.g., interplot in R)\n",
    "# but can extract model data and build own\n",
    "coefdf = DataFrame()\n",
    "coefdf.name = coefnames(m1a)[2:end] # no intercept\n",
    "coefdf.nameb = [\"Jokes\", \"Assault\"]\n",
    "coefdf.coef1 = coef(m1a)[2:end]\n",
    "coefdf.err1 = stderror(m1a)[2:end]\n",
    "coefdf.upper1 = coefdf.coef1 + 1.96*coefdf.err1\n",
    "coefdf.lower1 = coefdf.coef1 - 1.96*coefdf.err1\n",
    "coefdf.coef2 = coef(m1b)[2:end]\n",
    "coefdf.err2 = stderror(m1b)[2:end]\n",
    "coefdf.upper2 = coefdf.coef2 + 1.96*coefdf.err2\n",
    "coefdf.lower2 = coefdf.coef2 - 1.96*coefdf.err2\n",
    "\n",
    "coefdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function coefplot(m)\n",
    "       n = coefnames(m)[2:end] # no intercept\n",
    "       vals = coef(m)[2:end]\n",
    "       errors = stderror(m)[2:end]\n",
    "       scatter(\n",
    "           n,\n",
    "           vals,\n",
    "           #seriestype = :scatter,\n",
    "           #legend = false,\n",
    "           yerror = 1.96 .* errors,\n",
    "           title = \"Coefficient plot\"\n",
    "       )\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefplot(m1a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use int from package MLJBase\n",
    "plot(int(CategoricalArray(coefdf.name), type=Int), coefdf.coef1, seriestype = :scatter, yerror=1.96*coefdf.err1,\n",
    "    xtickfontsize=18,\n",
    "    ytickfontsize=18,\n",
    "    #xshowaxis=false,\n",
    "    xlabel=\"condition (Jokes, Assault)\",\n",
    "    xguidefontsize=18,\n",
    "    ylim = (-40,2),\n",
    "    ylabel=\"average treatment effect\",\n",
    "    yguidefontsize=18,\n",
    "    legendfontsize=18,\n",
    "    size=(1600,1600),\n",
    "        legend=false\n",
    "       )\n",
    "plot!(int(CategoricalArray(coefdf.name), type=Int).+.15, coefdf.coef2, seriestype = :scatter, yerror=1.96*coefdf.err2, lw=3\n",
    "       )\n",
    "hline!([0], seriestype = \"hline\", lw=2, ls=:dash, lc=\"black\")\n",
    "annotate!(1.1, -5, \"Assault\", :black)\n",
    "annotate!(2.1, -5, \"Jokes\", :black)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# switch to make horizontal, matching layout in publication\n",
    "plot(coefdf.coef1, int(CategoricalArray(coefdf.name), type=Int), seriestype = :scatter, xerror=1.96*coefdf.err1,\n",
    "    markersize=8,\n",
    "    xtickfontsize=18,\n",
    "    #ytickfontsize=18,\n",
    "    #tickfontcolor = false,\n",
    "    #yshowaxis=false,\n",
    "    xlabel=\"average treatment effect\",\n",
    "    xguidefontsize=18,\n",
    "    xlim = (-40,2),\n",
    "    ylabel=\"condition (Jokes, Assault)\",\n",
    "    #yguidefontsize=18,\n",
    "    label = (\"Same party\"),\n",
    "    legendfontsize=18,\n",
    "    #ytickfontcolor = \"white\",\n",
    "    ytickfontsize = 1, # eliminates tick labels\n",
    "    size=(1600,1600),\n",
    "    #legend=false,\n",
    "        legend = :left #:outertopleft\n",
    "       )\n",
    "plot!(coefdf.coef2, int(CategoricalArray(coefdf.name), type=Int).+.15, seriestype = :scatter, label = (\"Opposite party\"), \n",
    "            xerror=1.96*coefdf.err2, \n",
    "            markersize=8\n",
    "       )\n",
    "vline!([0], seriestype = \"vline\", lw=2, ls=:dash, lc=\"black\", label = false)\n",
    "annotate!(-5, 1.1, \"Assault\", :black)\n",
    "annotate!(-5, 2.1, \"Jokes\", :black)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "savefig(\"./figures/fig1.png\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m2a = lm(@formula(perchange_vote ~ condition2), samepartydat)\n",
    "m2b = lm(@formula(perchange_vote ~ condition2), opppartydat)\n",
    "m2a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m2b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefdf = DataFrame()\n",
    "coefdf.name = coefnames(m2a)[2:end] # no intercept\n",
    "coefdf.nameb = [\"Jokes\", \"Assault\"]\n",
    "coefdf.coef1 = coef(m2a)[2:end]\n",
    "coefdf.err1 = stderror(m2a)[2:end]\n",
    "coefdf.upper1 = coefdf.coef1 + 1.96*coefdf.err1\n",
    "coefdf.lower1 = coefdf.coef1 - 1.96*coefdf.err1\n",
    "coefdf.coef2 = coef(m2b)[2:end]\n",
    "coefdf.err2 = stderror(m2b)[2:end]\n",
    "coefdf.upper2 = coefdf.coef2 + 1.96*coefdf.err2\n",
    "coefdf.lower2 = coefdf.coef2 - 1.96*coefdf.err2\n",
    "\n",
    "coefdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(coefdf.coef1, int(CategoricalArray(coefdf.name), type=Int), seriestype = :scatter, xerror=1.96*coefdf.err1,\n",
    "    markersize=8,\n",
    "    xtickfontsize=18,\n",
    "    #ytickfontsize=18,\n",
    "    #tickfontcolor = false,\n",
    "    #yshowaxis=false,\n",
    "    xlabel=\"average treatment effect\",\n",
    "    xguidefontsize=18,\n",
    "    xlim = (-40,2),\n",
    "    ylabel=\"condition (Jokes, Assault)\",\n",
    "    #yguidefontsize=18,\n",
    "    label = (\"Same party\"),\n",
    "    legendfontsize=18,\n",
    "    #ytickfontcolor = \"white\",\n",
    "    ytickfontsize = 1,\n",
    "    size=(1600,1600),\n",
    "    #legend=false,\n",
    "        legend = :left #:outertopleft\n",
    "       )\n",
    "plot!(coefdf.coef2, int(CategoricalArray(coefdf.name), type=Int).+.15, seriestype = :scatter, label = (\"Opposite party\"), \n",
    "            xerror=1.96*coefdf.err2, \n",
    "            markersize=8\n",
    "       )\n",
    "vline!([0], seriestype = \"vline\", lw=2, ls=:dash, lc=\"black\", label = false)\n",
    "annotate!(-5, 1.1, \"Assault\", :black)\n",
    "annotate!(-5, 2.1, \"Jokes\", :black)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "savefig(\"./figures/fig2.png\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m3a = lm(@formula(perchange_sexism ~ condition2), samepartydat)\n",
    "m3b = lm(@formula(perchange_sexism ~ condition2), opppartydat)\n",
    "m3a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m3b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# juts need to change first two lines\n",
    "m1 = m3a\n",
    "m2 = m3b\n",
    "#\n",
    "coefdf = DataFrame()\n",
    "coefdf.name = coefnames(m1)[2:end] # no intercept\n",
    "coefdf.nameb = [\"Jokes\", \"Assault\"]\n",
    "coefdf.coef1 = coef(m1)[2:end]\n",
    "coefdf.err1 = stderror(m1)[2:end]\n",
    "coefdf.upper1 = coefdf.coef1 + 1.96*coefdf.err1\n",
    "coefdf.lower1 = coefdf.coef1 - 1.96*coefdf.err1\n",
    "coefdf.coef2 = coef(m2)[2:end]\n",
    "coefdf.err2 = stderror(m2)[2:end]\n",
    "coefdf.upper2 = coefdf.coef2 + 1.96*coefdf.err2\n",
    "coefdf.lower2 = coefdf.coef2 - 1.96*coefdf.err2\n",
    "\n",
    "coefdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(coefdf.coef1, int(CategoricalArray(coefdf.name), type=Int), seriestype = :scatter, xerror=1.96*coefdf.err1,\n",
    "    markersize=8,\n",
    "    xtickfontsize=18,\n",
    "    #ytickfontsize=18,\n",
    "    #tickfontcolor = false,\n",
    "    #yshowaxis=false,\n",
    "    xlabel=\"average treatment effect\",\n",
    "    xguidefontsize=18,\n",
    "    xlim = (-5,5),\n",
    "    ylabel=\"condition (Jokes, Assault)\",\n",
    "    yguidefontsize=18,\n",
    "    label = (\"Same party\"),\n",
    "    legendfontsize=18,\n",
    "    #ytickfontcolor = \"white\",\n",
    "    ytickfontsize = 1,\n",
    "    size=(1600,1600),\n",
    "    #legend=false,\n",
    "        legend = :left #:outertopleft\n",
    "       )\n",
    "plot!(coefdf.coef2, int(CategoricalArray(coefdf.name), type=Int).+.15, seriestype = :scatter, label = (\"Opposite party\"), \n",
    "            xerror=1.96*coefdf.err2, \n",
    "            markersize=8\n",
    "       )\n",
    "vline!([0], seriestype = \"vline\", lw=2, ls=:dash, lc=\"black\", label = false)\n",
    "annotate!(4, 1.1, \"Assault\", :black)\n",
    "annotate!(4, 2.1, \"Jokes\", :black)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "savefig(\"./figures/fig3.png\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sametempdf1 = samepartydat[(samepartydat[:condition2] .== \"Assault\"),:]\n",
    "sametempdf2 = samepartydat[(samepartydat[:condition2] .== \"Jokes\"),:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opptempdf1 = opppartydat[(opppartydat[:condition2] .== \"Assault\"),:]\n",
    "opptempdf2 = opppartydat[(opppartydat[:condition2] .== \"Jokes\"),:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sametempdf1[:mean] = mean(sametempdf1.meanpunishment)\n",
    "sametempdf1[:err] = std(sametempdf1.meanpunishment)\n",
    "sametempdf2[:mean] = mean(sametempdf2.meanpunishment)\n",
    "sametempdf2[:err] = std(sametempdf2.meanpunishment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opptempdf1[:mean] = mean(opptempdf1.meanpunishment)\n",
    "opptempdf1[:err] = std(opptempdf1.meanpunishment)\n",
    "opptempdf2[:mean] = mean(opptempdf2.meanpunishment)\n",
    "opptempdf2[:err] = std(opptempdf2.meanpunishment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tempdf1 = DataFrame()\n",
    "tempdf1[:mean] = [sametempdf1.mean[1], sametempdf2.mean[1]]\n",
    "tempdf1.condition2 = [\"Assault\", \"Jokes\"]\n",
    "tempdf1.err = [sametempdf1.err[1], sametempdf2.err[1]]\n",
    "tempdf1\n",
    "\n",
    "tempdf2 = DataFrame()\n",
    "tempdf2[:mean] = [opptempdf1.mean[1], opptempdf2.mean[1]]\n",
    "tempdf2.condition2 = [\"Assault\", \"Jokes\"]\n",
    "tempdf2.err = [opptempdf1.err[1], opptempdf2.err[1]]\n",
    "tempdf2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g1 = plot(int(CategoricalArray(tempdf1.condition2), type=Int), tempdf1.mean, seriestype = :scatter, yerror=1.44*tempdf1.err,\n",
    "        markersize=8,\n",
    "    ytickfontsize=18,\n",
    "    #ytickfontsize=18,\n",
    "    #tickfontcolor = false,\n",
    "    #yshowaxis=false,\n",
    "    ylabel=\"mean punitiveness\",\n",
    "    yguidefontsize=18,\n",
    "    ylim = (1,5),\n",
    "    xlabel=\"condition (Jokes, Assault)\",\n",
    "    #xguidefontsize=18,\n",
    "    label = (\"Same party\"),\n",
    "    legendfontsize=18,\n",
    "    #ytickfontcolor = \"white\",\n",
    "    xtickfontsize = 1,\n",
    "    size=(1600,1600),\n",
    "    legend=false\n",
    "    #legend = :left #:outertopleft,\n",
    "    )\n",
    "hline!([0], seriestype = \"vline\", lw=2, ls=:dash, lc=\"black\", label = false)\n",
    "#annotate!(4, 1.1, \"Assault\", :black)\n",
    "g2 = plot(int(CategoricalArray(tempdf2.condition2), type=Int), tempdf2.mean, seriestype = :scatter, yerror=1.44*tempdf2.err,\n",
    "         markersize=8,\n",
    "    ytickfontsize=18,\n",
    "    #ytickfontsize=18,\n",
    "    #tickfontcolor = false,\n",
    "    #yshowaxis=false,\n",
    "    ylabel=\"mean punitiveness\",\n",
    "    yguidefontsize=18,\n",
    "    ylim = (1,5),\n",
    "    xlabel=\"condition (Jokes, Assault)\",\n",
    "    #xguidefontsize=18,\n",
    "    label = (\"Same party\"),\n",
    "    legendfontsize=18,\n",
    "    #ytickfontcolor = \"white\",\n",
    "    xtickfontsize = 1,\n",
    "    size=(1600,1600),\n",
    "    legend=false\n",
    "    #    legend = :left #:outertopleft\n",
    "    )\n",
    "hline!([0], seriestype = \"vline\", lw=2, ls=:dash, lc=\"black\", label = false)\n",
    "#annotate!(4, 1.1, \"Assault\", :black)\n",
    "plot(g1, g2)\n",
    "\n",
    "# l = @layout [a ; b c]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "savefig(\"./figures/fig4.png\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using JLD\n",
    "#@save \"./data/working/working.jld\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use julia's plotting logic to plot two graphs side by side"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# desccribe(df1.pre_sexism)\n",
    "# pre_sexism ranges from 1-5 and increases in small increments\n",
    "# so draw random sample of 500 obs from uniform distribution between 1-5\n",
    "MVZ = rand((1: 0.01 :5),500)\n",
    "MVZ = sort(MVZ)\n",
    "plot(MVZ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m5  = lm(@formula(perchange_favorability ~ condition2 + pre_sexism + condition2*pre_sexism), df1)\n",
    "# put the in dataframe and add other vars\n",
    "intdf = DataFrame()\n",
    "intdf[:MVZ] = MVZ\n",
    "intdf[:b1] = coef(m5)[2]\n",
    "intdf[:b2] = coef(m5)[3]\n",
    "intdf[:b4] = coef(m5)[5]\n",
    "intdf[:b5] = coef(m5)[6]\n",
    "# model matrix is:\n",
    "mm = ModelMatrix(ModelFrame(@formula(perchange_favorability ~ condition2 + pre_sexism + condition2*pre_sexism), df1))\n",
    "#var-cov matrix is:\n",
    "varcovm5 = mm\n",
    "#varcovm5\n",
    "intdf[:varb1] = varcovm5[1,1]\n",
    "intdf[:varb2] = varcovm5[2,2]\n",
    "intdf[:varb4] = varcovm5[4,4]\n",
    "intdf[:varb5] = varcovm5[5,5]\n",
    "intdf[:covb1b4] =  varcovm5[1,4]\n",
    "intdf[:covb2b5] =  varcovm5[2,5]\n",
    "intdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intdf[:conbx1]=intdf.b1+(intdf.b4*intdf.MVZ)\n",
    "intdf[:consx1]=(intdf.varb1+(intdf.varb4*(intdf.MVZ**2))+2*intdf.covb1b4*intdf.MVZ)**.5 # could also use ** to calc sqrt\n",
    "intdf[:err1]=1.96*intdf.consx1\n",
    "intdf[:upperx1]=intdf.conbx1+intdf.err1\n",
    "intdf[:lowerx1]=intdf.conbx1-intdf.err1 # could separate multiple statements with semi-colon (;)\n",
    "\n",
    "intdf[:conbx2]=intdf.b2+(intdf.b5*intdf.MVZ)\n",
    "intdf[:consx2]=(intdf.varb2+(intdf.varb5*(intdf.MVZ**2))+2*intdf.covb2b5*intdf.MVZ)**.5 # could also use ** to calc sqrt\n",
    "intdf[:err2]=1.96*intdf.consx2\n",
    "intdf[:upperx2]=intdf.conbx2+intdf.err2\n",
    "intdf[:lowerx2]=intdf.conbx2-intdf.err2 # could separate multiple statements with semi-colon (;)\n",
    "intdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# diagnostics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using StatPlots, Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@df df2 corrplot([:condition2 :pre_sexism :meanpunishment :post_vote], grid = false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.5.3",
   "language": "julia",
   "name": "julia-1.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
